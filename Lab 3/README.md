

\*\***Write your own shell file to use your favorite of these TTS engines to have your Pi greet you by name.**\*\*

#### My bash file is called greet_me.sh

### Speech to Text


\*\***Write your own shell file that verbally asks for a numerical based input (such as a phone number, zipcode, number of pets, etc) and records the answer the respondent provides.**\*\*

#### My file is called pet_demo.sh. It asks how many pets you have and prints "Wow [insert pet number] is a lot of pets!"

### Serving Pages

### Storyboard

\*\***Post your storyboard and diagram here.**\*\*
Here is my storyboard [link](https://drive.google.com/file/d/1x0rJGo33331CZYj8sHRHrOQI042XcoxG/view?usp=sharing)

The device listens to you as you speak and corrects you when you say filler words such as "like" "um", and "so". The prupose of this device is to make you more confident and clear when you speak. 

\*\***Please describe and document your process.**\*\*

We started thinking of ways that a personal voice assistant could be of use in our daily lives. I often find myself wishing I had phrased things differently during presentations, interviews, and conversations. It would be great to get immediate feedback on the way I speak so that I can speak in a more confident and concise manner. The device would listen to my dialog in real-time as I prepare for for presentatinos and interviews and give me feedback directly. Alternatively, it could record my live presentations and later give me feedback without interrupting me. 


### Acting out the dialogue

Find a partner, and *without sharing the script with your partner* try out the dialogue you've designed, where you (as the device designer) act as the device you are designing.  Please record this interaction (for example, using Zoom's record feature).

The device's responses are generated on the fly. For our interview, I pretended to give a presentation on how to cook chicken, and my partner Patricio, aka the device, interrupted me to correct my phrasing (the correction is unknown to me as the user).


\*\***Describe if the dialogue seemed different than what you imagined when it was acted out, and how.**\*\*


# Lab 3 Part 2

For Part 2, you will redesign the interaction with the speech-enabled device using the data collected, as well as feedback from part 1.

## Prep for Part 2

1. What are concrete things that could use improvement in the design of your device? For example: wording, timing, anticipation of misunderstandings...
2. What are other modes of interaction _beyond speech_ that you might also use to clarify how to interact?
3. Make a new storyboard, diagram and/or script based on these reflections.

## Prototype your system

The system should:
* use the Raspberry Pi 
* use one or more sensors
* require participants to speak to it. 

*Document how the system works*

*Include videos or screencaptures of both the system and the controller.*

## Test the system
Try to get at least two people to interact with your system. (Ideally, you would inform them that there is a wizard _after_ the interaction, but we recognize that can be hard.)

Answer the following:

### What worked well about the system and what didn't?
\*\**your answer here*\*\*

### What worked well about the controller and what didn't?

\*\**your answer here*\*\*

### What lessons can you take away from the WoZ interactions for designing a more autonomous version of the system?

\*\**your answer here*\*\*


### How could you use your system to create a dataset of interaction? What other sensing modalities would make sense to capture?

\*\**your answer here*\*\*

